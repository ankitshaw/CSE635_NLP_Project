{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "aHW-SPAJVllU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is BERT?**"
      ],
      "metadata": {
        "id": "7sdKzvv7VllZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT is a deep learning model that has given state-of-the-art results on a wide variety of natural language processing tasks. It stands for Bidirectional Encoder Representations for Transformers. It has been pre-trained on Wikipedia and BooksCorpus and requires task-specific fine-tuning**"
      ],
      "metadata": {
        "id": "EeC-t3njVllZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Why BERT?**"
      ],
      "metadata": {
        "id": "eZywk12qVlla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* BERT was built upon recent work and clever ideas in pre-training contextual representations including Semi-supervised Sequence Learning, Generative Pre-Training, ELMo, the OpenAI Transformer, ULMFit and the Transformer. Although these models are all unidirectional or shallowly bidirectional, BERT is fully bidirectional.\n",
        "* BERT gives it incredible accuracy and performance on smaller data sets which solves a huge problem in natural language processing."
      ],
      "metadata": {
        "id": "9MhkeRN6Vlla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. How does it work?**"
      ],
      "metadata": {
        "id": "GeJB3I-EVlla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT relies on a Transformer (the attention mechanism that learns contextual relationships between words in a text). A basic Transformer consists of an encoder to read the text input and a decoder to produce a prediction for the task. Since BERT’s goal is to generate a language representation model, it only needs the encoder part. The input to the encoder for BERT is a sequence of tokens, which are first converted into vectors and then processed in the neural network. But before processing can start, BERT needs the input to be massaged and decorated with some extra metadata:\n",
        "\n",
        "1. Token embeddings: A [CLS] token is added to the input word tokens at the beginning of the first sentence and a [SEP] token is inserted at the end of each sentence.\n",
        "2. Segment embeddings: A marker indicating Sentence A or Sentence B is added to each token. This allows the encoder to distinguish between sentences.\n",
        "3. Positional embeddings: A positional embedding is added to each token to indicate its position in the sentence."
      ],
      "metadata": {
        "id": "AQRyIrt2Vlla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. How to use BERT?**"
      ],
      "metadata": {
        "id": "91ko0EaSVlla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT can be used for a wide variety of language tasks, while only adding a small layer to the core model**\n",
        "\n",
        "1. Classification tasks such as sentiment analysis are done similarly to Next Sentence classification, by adding a classification layer on top of the Transformer output for the [CLS] token.\n",
        "\n",
        "2. In Question Answering tasks (e.g. SQuAD v1.1), the software receives a question regarding a text sequence and is required to mark the answer in the sequence. Using BERT, a Q&A model can be trained by learning two extra vectors that mark the beginning and the end of the answer.\n",
        "\n",
        "3. In Named Entity Recognition (NER), the software receives a text sequence and is required to mark the various types of entities (Person, Organization, Date, etc) that appear in the text. Using BERT, a NER model can be trained by feeding the output vector of each token into a classification layer that predicts the NER label."
      ],
      "metadata": {
        "id": "vQ3VOtXwVlla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries and Data** "
      ],
      "metadata": {
        "id": "6MuKCEwnVllb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "pjzydkU1Vllb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import BERT tokenization\n",
        "\n",
        "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
      ],
      "metadata": {
        "trusted": true,
        "id": "dvggWM_qVllb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenization\n",
        "!pip install bert-tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0erY8KRsWPQb",
        "outputId": "e94b3c7d-bded-4714-8154-ee6ab9e391e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tokenization in /usr/local/lib/python3.9/dist-packages (1.0.7)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from tokenization) (2022.10.31)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bert-tensorflow\n",
            "  Downloading bert_tensorflow-1.0.4-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from bert-tensorflow) (1.16.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tokenization\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras.utils import to_categorical\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "trusted": true,
        "id": "aI64j6KIVllb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bert import tokenization"
      ],
      "metadata": {
        "id": "JAWswndYYnFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"/content/intent_class_dataset\"\n",
        "data = pd.read_csv(filepath)"
      ],
      "metadata": {
        "trusted": true,
        "id": "AXThkfjgVllb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop('Unnamed: 0', axis='columns')\n",
        "data.head()"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uj8crsa_Vllb",
        "outputId": "7c09d433-1519-43c6-89d5-52d6ad792df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              parent_id  \\\n",
              "0  a07edb12-6b91-4138-b11e-02421888d699   \n",
              "1  720840be-e522-47ba-9e9f-143f66372673   \n",
              "2  720840be-e522-47ba-9e9f-143f66372673   \n",
              "3  549cc1d1-270e-4a53-b561-133a8d0086b4   \n",
              "4  549cc1d1-270e-4a53-b561-133a8d0086b4   \n",
              "\n",
              "                                              parent    intent  \n",
              "0  What's one thing your best friend doesn't know...  chitchat  \n",
              "1                                              Hello  chitchat  \n",
              "2                           How are you doing today?  chitchat  \n",
              "3                                        whats up MD  chitchat  \n",
              "4                                      im doing good  chitchat  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-faf20b51-c3c5-4ab5-ac80-0f35e0fdd50e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>parent_id</th>\n",
              "      <th>parent</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a07edb12-6b91-4138-b11e-02421888d699</td>\n",
              "      <td>What's one thing your best friend doesn't know...</td>\n",
              "      <td>chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>720840be-e522-47ba-9e9f-143f66372673</td>\n",
              "      <td>Hello</td>\n",
              "      <td>chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>720840be-e522-47ba-9e9f-143f66372673</td>\n",
              "      <td>How are you doing today?</td>\n",
              "      <td>chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>549cc1d1-270e-4a53-b561-133a8d0086b4</td>\n",
              "      <td>whats up MD</td>\n",
              "      <td>chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>549cc1d1-270e-4a53-b561-133a8d0086b4</td>\n",
              "      <td>im doing good</td>\n",
              "      <td>chitchat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-faf20b51-c3c5-4ab5-ac80-0f35e0fdd50e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-faf20b51-c3c5-4ab5-ac80-0f35e0fdd50e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-faf20b51-c3c5-4ab5-ac80-0f35e0fdd50e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Label encoding of labels**"
      ],
      "metadata": {
        "id": "EFzPIJ_2Vllb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = preprocessing.LabelEncoder()\n",
        "y = label.fit_transform(data['intent'])\n",
        "y = to_categorical(y)\n",
        "print(y[:5])"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoWn8en8Vllb",
        "outputId": "77e2e7a2-22b5-443d-903d-d031adfcd674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.copy()\n",
        "X = X.drop('intent', axis='columns')\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7aEXQgjBXlz5",
        "outputId": "ec1871a8-047f-4135-fa4b-00709cc40fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              parent_id  \\\n",
              "0  a07edb12-6b91-4138-b11e-02421888d699   \n",
              "1  720840be-e522-47ba-9e9f-143f66372673   \n",
              "2  720840be-e522-47ba-9e9f-143f66372673   \n",
              "3  549cc1d1-270e-4a53-b561-133a8d0086b4   \n",
              "4  549cc1d1-270e-4a53-b561-133a8d0086b4   \n",
              "\n",
              "                                              parent  \n",
              "0  What's one thing your best friend doesn't know...  \n",
              "1                                              Hello  \n",
              "2                           How are you doing today?  \n",
              "3                                        whats up MD  \n",
              "4                                      im doing good  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee5c6179-9a9e-45a4-aeae-bce45ce6bd79\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>parent_id</th>\n",
              "      <th>parent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a07edb12-6b91-4138-b11e-02421888d699</td>\n",
              "      <td>What's one thing your best friend doesn't know...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>720840be-e522-47ba-9e9f-143f66372673</td>\n",
              "      <td>Hello</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>720840be-e522-47ba-9e9f-143f66372673</td>\n",
              "      <td>How are you doing today?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>549cc1d1-270e-4a53-b561-133a8d0086b4</td>\n",
              "      <td>whats up MD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>549cc1d1-270e-4a53-b561-133a8d0086b4</td>\n",
              "      <td>im doing good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee5c6179-9a9e-45a4-aeae-bce45ce6bd79')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ee5c6179-9a9e-45a4-aeae-bce45ce6bd79 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ee5c6179-9a9e-45a4-aeae-bce45ce6bd79');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "Iu_iztM7XSdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build a BERT layer**"
      ],
      "metadata": {
        "id": "U_W0VJE5Vllb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we create a BERT embedding layer by importing the BERT model from hub.KerasLayer"
      ],
      "metadata": {
        "id": "wnWVDH_GVllb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\n",
        "bert_layer = hub.KerasLayer(m_url, trainable=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ij5JUviqVllb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoding the text**"
      ],
      "metadata": {
        "id": "p-V6rNqYVllb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we create a BERT vocab_file in the form a numpy array. We then set the text to lowercase and finally we pass our vocab_file and do_lower_case variables to the Tokenizer object."
      ],
      "metadata": {
        "id": "JVoCtrMUVllb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
        "\n",
        "def bert_encode(texts, tokenizer, max_len=512):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "        \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len-len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "        \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZNBTrmXDVllc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build The Model**"
      ],
      "metadata": {
        "id": "RmUH9iEhVllc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are all set to create our model. To do so, we will create a function named build_model that having tf.keras.models.Model class. Inside the function we will define our model layers. Our model will consist of three **Dense** neural network layers and also dropout layer. We have chosen a learning rate to 1e-5.\n",
        "\n",
        "**RELU function** :- \n",
        "With default values, this returns max(x, 0), the element-wise maximum of 0 and the input tensor.\n",
        "Modifying default parameters allows you to use non-zero thresholds, change the max value of the activation, and to use a non-zero multiple of the input for values below the threshold.\n",
        "\n",
        "\n",
        "**Softmax function** :-\n",
        "Softmax converts a real vector to a vector of categorical probabilities.\n",
        "The elements of the output vector are in range (0, 1) and sum to 1.\n",
        "Each vector is handled independently. The axis argument sets which axis of the input the function is applied along.\n",
        "Softmax is often used as the activation for the last layer of a classification network because the result could be interpreted as a probability distribution.\n",
        "The softmax of each vector x is computed as exp(x) / tf.reduce_sum(exp(x)).\n",
        "\n",
        "**Binary corssentropy**:-\n",
        "Computes the cross-entropy loss between true labels and predicted labels.\n",
        "We can use this cross-entropy loss when there are only two label classes (assumed to be 0 and 1). For each example, there should be a single floating-point value per prediction."
      ],
      "metadata": {
        "id": "bGxVTDMXVllc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(bert_layer, max_len=512):\n",
        "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
        "    \n",
        "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "    \n",
        "    clf_output = sequence_output[:, 0, :]\n",
        "    \n",
        "    lay = tf.keras.layers.Dense(64, activation='relu')(clf_output)\n",
        "    lay = tf.keras.layers.Dropout(0.2)(lay)\n",
        "    lay = tf.keras.layers.Dense(32, activation='relu')(lay)\n",
        "    lay = tf.keras.layers.Dropout(0.2)(lay)\n",
        "    out = tf.keras.layers.Dense(5, activation='softmax')(lay)\n",
        "    \n",
        "    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
        "    model.compile(tf.keras.optimizers.Adam(lr=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "id": "lt0CA9nlVllc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here We check only the first 250 characters of each text, and also we set train-test input and train labels"
      ],
      "metadata": {
        "id": "6Wn-5fKEVllc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 250\n",
        "train_input = bert_encode(X_train, tokenizer, max_len=max_len)\n",
        "test_input = bert_encode(X_test, tokenizer, max_len=max_len)\n",
        "train_labels = y_train"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "LKTU8WDNVllc",
        "outputId": "1eb207e4-9f92-4a43-9894-1d55ea8f27ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnparsedFlagAccessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnparsedFlagAccessError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-d723855bebcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-a64ed504e74e>\u001b[0m in \u001b[0;36mbert_encode\u001b[0;34m(texts, tokenizer, max_len)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/bert/tokenization.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    190\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mpreserve_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0msplit_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/bert/tokenization.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morig_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mpreserve_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0msplit_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/bert/tokenization.py\u001b[0m in \u001b[0;36mpreserve_token\u001b[0;34m(token, vocab)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreserve_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;34m\"\"\"Returns True if the token should forgo tokenization and be preserved.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_unused_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    479\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m       raise _exceptions.UnparsedFlagAccessError(\n\u001b[0m\u001b[1;32m    482\u001b[0m           'Trying to access flag --%s before flags were parsed.' % name)\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnparsedFlagAccessError\u001b[0m: Trying to access flag --preserve_unused_tokens before flags were parsed."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = label.classes_\n",
        "print(labels)"
      ],
      "metadata": {
        "trusted": true,
        "id": "-s4ZN-60Vllc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(bert_layer, max_len=max_len)\n",
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "cYnssgtrVllc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run the model**"
      ],
      "metadata": {
        "id": "xRu25AWVVllc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\n",
        "\n",
        "train_sh = model.fit(\n",
        "    train_input, train_labels,\n",
        "    validation_split=0.2,\n",
        "    epochs=3,\n",
        "    callbacks=[checkpoint, earlystopping],\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "5__7jHyCVllc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}